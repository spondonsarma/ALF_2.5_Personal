% Copyright (c) 2016 The ALF project.
% This is a part of the ALF project documentation.
% The ALF project documentation by the ALF contributors is licensed
% under a Creative Commons Attribution-ShareAlike 4.0 International License.
% For the licensing details of the documentation see license.CCBYSA.

% !TEX root = Doc.tex


%------------------------------------------------------------
\subsection{Formulation of the QMC}  
%------------------------------------------------------------
We would like to study observables in  thermodynamic equilibrium. 
To describe the quantum statistical behavior induced by the general Hamiltonian (\ref{eqn:general_ham})
we conveniently use the  grand-canonical probability distribution of internal energies of the system. 
The quantum nature of the Hamiltonian with $d$ space dimensions is captured by the additional imaginary time dimension, 
resulting in a $d+1$-dimensional quantum system. 
Upon evenly discretizing the imaginary axis and upon applying a Hubbard-Stratonovich  transformation \cite{Hubbard59} to the interacting density operators, 
the grand-canonical partition function becomes a functional integral in the domain $\mathcal{C}$ of space- and time-dependent auxiliary fields $\phi(i,\tau)$:
\begin{equation}
Z = \Tr{\left(e^{-\beta \hat{\mathcal{H}} }\right)}
= \int_{\mathcal{C}}\mathrm{d}\phi \;e^{-S[\phi]}
\end{equation}
In order to calculate expectation values, we sample the configuration space $\mathcal{C}$  with the standard Markov chain Monte Carlo method using the Metropolis algorithm \cite{Metropolis, Kennedy, Binder}. 
By default, the auxiliary fields are updated one after the other by moving sequentially through the space-time lattice.
\mycomment{MB: do we want to comment on the absence of detailed balance? }

The outline of this section is as follows. First, we derive the detailed form of the partition function and outline the computation of observables (Sec.~\ref{sec:part} -\ref{sec:reweight}). 
Next, we present a number of update strategies, namely local updates, global updates, and parallel tempering (Sec.~\ref{sec:updating}). 
We equally discuss the measures we have implemented to make the code numerical stable (Sec.~\ref{sec:stable}). Finally, we discuss the autocorrelations and associated time scales during 
Monte Carlo sampling process (Sec.~\ref{sec:sampling}). 

The essential ingredients of the auxiliary field quantum Monte Carlo implementation in the ALF package are the following:
\begin{itemize}
\item  We will discretize the imaginary time propagation: $\beta = \Delta \tau L_{\text{Trotter}} $ \cite{Fye86}
\item  We will use  the   discrete Hubbard-Stratonovich transformation \cite{Motome97,Assaad97}:
\begin{equation}
\label{HS_squares}
        e^{\Delta \tau  \lambda  \hat{A}^2 } =
        \sum_{ l = \pm 1, \pm 2}  \gamma(l)
e^{ \sqrt{\Delta \tau \lambda }
       \eta(l)  \hat{A} }
                + {\cal O} (\Delta \tau ^4)\;,
\end{equation}
where the fields $\eta$ and $\gamma$ take the values:
\begin{eqnarray}
 \gamma(\pm 1)  = 1 + \sqrt{6}/3, \quad  \eta(\pm 1 ) = \pm \sqrt{2 \left(3 - \sqrt{6} \right)}\;,\\\nonumber
  \gamma(\pm 2) = 1 - \sqrt{6}/3, \quad  \eta(\pm 2 ) = \pm \sqrt{2 \left(3 + \sqrt{6} \right)}\;.
\nonumber
\end{eqnarray}
\item  We will work in  a basis for the Ising spins  where  $\hat{Z}_k$ is diagonal: $\hat{Z}_{k}|s_{k}\rangle = s_{k}|s_{k}\rangle$, where $s_{k}=\pm 1$.
\item From the above it follows that the  Monte Carlo configuration space $C$  
is given by the combined spaces of Ising spin configurations  and of Hubbard-Stratonovich discrete field configurations:
\begin{equation}
	C = \left\{   s_{i,\tau} ,  l_{j,\tau}  \text{ with }  i=1\cdots M_I,\;  j = 1\cdots M_V,\; \tau=1\cdots L_{\mathrm{Trotter}}  \right\}
\end{equation}
Here, the Ising spins take the values  $s_{i,\tau} = \pm 1$ and  the Hubbard-Stratonovich fields take the values  $l_{j,\tau}  = \pm 2, \pm 1 $.
\end{itemize}

%------------------------------------------------------------
\subsubsection{The partition function}\label{sec:part}
%------------------------------------------------------------

With the above, the partition function of the model (\ref{eqn:general_ham}) can be written as follows.
\begin{eqnarray}\label{eqn:partition_1}
Z &=& \Tr{\left(e^{-\beta \hat{\mathcal{H}} }\right)}\nonumber\\
  &=&   \Tr{  \left[ e^{-\Delta \tau \hat{\mathcal{H}}_{0,I}}   \prod_{k=1}^{M_T}   e^{-\Delta \tau \hat{T}^{(k)}}  
    \prod_{k=1}^{M_V}   e^{ - \Delta \tau  U_k \left(  \hat{V}^{(k)} \right)^2}   \prod_{k=1}^{M_I}   e^{  -\Delta \tau  \hat{\sigma}_{k}  \hat{I}^{(k)}} 
   \right]^{L_{\text{Trotter}}}}  + \mathcal{O}(\Delta\tau^{2})\nonumber \\
   &=&
   \sum_{C} \left( \prod_{k=1}^{M_V} \prod_{\tau=1}^{L_{\mathrm{Trotter}}} \gamma_{k,\tau} \right) e^{-S_{0,I} \left( \left\{ s_{i,\tau} \right\}  \right) }\times \nonumber\\
   &\quad&
    \Trf{ \left\{  \prod_{\tau=1}^{L_{\mathrm{Trotter}}} \left[   \prod_{k=1}^{M_T}   e^{-\Delta \tau \hat{T}^{(k)}}  
    \prod_{k=1}^{M_V}   e^{  \sqrt{ -\Delta \tau  U_k} \eta_{k,\tau} \hat{V}^{(k)} }   \prod_{k=1}^{M_I}   e^{  -\Delta \tau s_{k,\tau}  \hat{I}^{(k)}}  \right]\right\} }+ \mathcal{O}(\Delta\tau^{2})\;.
\end{eqnarray}
In the above,  the trace $\mathrm{Tr} $  runs over the Ising spins as well as over the fermionic degrees of freedom, and $ \mathrm{Tr}_{\mathrm{F}}  $ only over the  fermionic Fock space. 
$S_{0,I} \left( \left\{ s_{i,\tau} \right\}  \right)  $ is the action  corresponding to the Ising Hamiltonian,  and is only dependent on the Ising spins so that  it can be pulled out of the fermionic trace.  We have adopted the short hand notation $\eta_{k,\tau}  = \eta(l_{k,\tau})$   and $\gamma_{k,\tau}  = \gamma(l_{k,\tau})$.
At this point,  and  since for a given configuration $C$  we are dealing with a free propagation, we can integrate out the fermions to obtain a determinant: 
\begin{eqnarray}
 &\quad&\Trf{ \left\{  \prod_{\tau=1}^{L_{\mathrm{Trotter}}} \left[   \prod_{k=1}^{M_T}   e^{-\Delta \tau \hat{T}^{(k)}}  
    \prod_{k=1}^{M_V}   e^{  \sqrt{ - \Delta \tau  U_k} \eta_{k,\tau} \hat{V}^{(k)} }   \prod_{k=1}^{M_I}   e^{  -\Delta \tau s_{k,\tau}  \hat{I}^{(k)}}  \right] \right\}} = \nonumber\\
&\quad& \quad\prod\limits_{s=1}^{N_{\mathrm{fl}}} \left[  e^{\sum\limits_{k=1}^{M_V} \sum\limits_{\tau = 1}^{L_{\mathrm{Trotter}}}\sqrt{-\Delta \tau U_k}  \alpha_{k,s} \eta_{k,\tau} }
   \right]^{N_{\mathrm{col}}}\times
\nonumber\\
&\quad&\quad   \prod\limits_{s=1}^{N_{\mathrm{fl}}} 
   \left[
    \det\left(  \mathds{1} + 
     \prod_{\tau=1}^{L_{\mathrm{Trotter}}}   \prod_{k=1}^{M_T}   e^{-\Delta \tau \textbf{T}^{(ks)}}  
    \prod_{k=1}^{M_V}   e^{  \sqrt{ -\Delta \tau  U_k} \eta_{k,\tau} {\bm V}^{(ks)} }   \prod_{k=1}^{M_I}   e^{  -\Delta \tau s_{k,\tau}  {\bm I}^{(ks)}}  
     \right) \right]^{N_{\mathrm{col}}}\;,
\end{eqnarray}
where the matrices $\textbf{T}^{(ks)}$,  $\textbf{V}^{(ks)}$, and  $\textbf{I}^{(ks)}$ define the Hamiltonian [Eq.~(\ref{eqn:general_ham}) - (\ref{eqn:general_ham_i})].
All in all,   the partition function is given by:
\begin{eqnarray}\label{eqn:partition_2}
    Z  &=&   \sum_{C}   e^{-S_{0,I} \left( \left\{ s_{i,\tau} \right\}  \right) }     \left( \prod_{k=1}^{M_V} \prod_{\tau=1}^{L_{\mathrm{Trotter}}} \gamma_{k,\tau} \right)
    e^{ N_{\mathrm{col}}\sum\limits_{s=1}^{N_{\mathrm{fl}}} \sum\limits_{k=1}^{M_V} \sum\limits_{\tau = 1}^{L_{\mathrm{Trotter}}}\sqrt{-\Delta \tau U_k}  \alpha_{k,s} \eta_{k,\tau} } 
  \times   \nonumber \\
  &\quad&
      \prod_{s=1}^{N_{\mathrm{fl}}}\left[\det\left(  \mathds{1} + 
     \prod_{\tau=1}^{L_{\mathrm{Trotter}}}   \prod_{k=1}^{M_T}   e^{-\Delta \tau {\bm T}^{(ks)}}  
    \prod_{k=1}^{M_V}   e^{  \sqrt{ -\Delta \tau  U_k} \eta_{k,\tau} {\bm V}^{(ks)} }   \prod_{k=1}^{M_I}   e^{  -\Delta \tau s_{k,\tau}  {\bm I}^{(ks)}}  
     \right) \right]^{N_{\mathrm{col}}}  \nonumber \\ 
     & \equiv&  \sum_{C} e^{-S(C) }\;.
\end{eqnarray}
In the above, one notices that the weight factorizes in  the flavor index. The color index raises the determinant to the power $N_{\mathrm{col}}$. 
This corresponds to  an explicit $SU(N_{\mathrm{col}})$ symmetry   for each  configuration. This symmetry is manifest in the fact that the single particle  Green functions are color independent, again for each given  configuration $C$.

%------------------------------------------------------------
\subsubsection{Observables}\label{Observables.General}
%------------------------------------------------------------

In the auxiliary field QMC approach, the single particle Green function plays a crucial role.  It determines the Monte Carlo dynamics and is used to compute  observables:
\begin{equation}\label{eqn:obs}
\langle \hat{O}  \rangle  = \frac{ \text{Tr}   \left[ e^{- \beta \hat{H}}  \hat{O}   \right] }{ \text{Tr}   \left[ e^{- \beta \hat{H}}  \right] } =   \sum_{C}   P(C) 
   \langle \langle \hat{O}  \rangle \rangle_{(C)} , \text{   with   } 
  P(C)   = \frac{ e^{-S(C)}}{\sum_C e^{-S(C)}}\;,
\end{equation}
and $\langle \langle \hat{O}  \rangle \rangle_{(C)} $ denotes the observed value of $\hat{O}$ for a given configuration $C$.
For a given configuration $C$  one can use Wicks theorem to compute $O (C) $   from the knowledge of the single particle Green function: 
\begin{equation}
       G( x,\sigma,s, \tau |    x',\sigma',s', \tau')   =       \langle \langle {\cal T} \hat{c}^{\phantom\dagger}_{x \sigma s} (\tau)  \hat{c}^{\dagger}_{x' \sigma' s'} (\tau') \rangle \rangle_{C}
\end{equation}
where $ {\cal T} $ corresponds to the imaginary time ordering operator.   The  corresponding equal time quantity reads, 
\begin{equation}
       G( x,\sigma,s, \tau |    x',\sigma',s', \tau)   =       \langle \langle  \hat{c}^{\phantom\dagger}_{x \sigma s} (\tau)  \hat{c}^{\dagger}_{x' \sigma' s'} (\tau) \rangle \rangle_{C}.
\end{equation}
Since  for a given HS field translation invariance in imaginary time is broken, the Green function has an explicit $\tau$ and $\tau'$ dependence.   On the other hand it is diagonal in the flavor index, and independent on the color index. The later reflects the  explicit SU(N)   color symmetry present at the level of individual HS configurations.   As an example,  one can show that the equal time Green function at $\tau = 0$ reads:
\begin{equation}
G(x,\sigma,s,0| x',\sigma,s,0 )  =   \left(  1  +  \prod_{\tau = 1}^{L_{\text{Trotter}}}  B_{\tau}^{(s)}   \right)^{-1}_{x,x'}
\end{equation}
with
\begin{equation}
	B_{\tau}^{(s)} =  \prod_{k=1}^{M_T}   e^{-\Delta \tau {\bm T}^{(ks)}}  
    \prod_{k=1}^{M_V}   e^{  \sqrt{ -\Delta \tau  U_k} \eta_{k,\tau} {\bm V}^{(ks)} }   \prod_{k=1}^{M_I}   e^{  -\Delta \tau s_{k,\tau}  {\bm I}^{(ks)}}.
\end{equation}


To compute equal time as well as time-displaced observables,  one can make use of Wicks theorem. A convenient formulation of this theorem for  QMC simulations reads: 
\begin{eqnarray}
& & \langle \langle 	{\cal T}   c^{\dagger}_{\underline x_{1}}(\tau_{1}) c^{\phantom\dagger}_{{\underline x}'_{1}}(\tau'_{1})  
\cdots c^{\dagger}_{\underline x_{n}}(\tau_{n}) c^{\phantom\dagger}_{{\underline x}'_{n}}(\tau'_{n}) 
\rangle \rangle_{C} =
\nonumber \\ & & \det  
\begin{bmatrix}
   \langle \langle   {\cal T}   c^{\dagger}_{\underline x_{1}}(\tau_{1}) c^{\phantom\dagger}_{{\underline x}'_{1}}(\tau'_{1})  \rangle \rangle_{C} & 
    \langle \langle  {\cal T}   c^{\dagger}_{\underline x_{1}}(\tau_{1}) c^{\phantom\dagger}_{{\underline x}'_{2}}(\tau'_{2})  \rangle \rangle_{C}  & \dots   &   
    \langle \langle   {\cal T}   c^{\dagger}_{\underline x_{1}}(\tau_{1}) c^{\phantom\dagger}_{{\underline x}'_{n}}(\tau'_{n})  \rangle \rangle_{C}  \\
    \langle \langle   {\cal T}   c^{\dagger}_{\underline x_{2}}(\tau_{2}) c^{\phantom\dagger}_{{\underline x}'_{1}}(\tau'_{1})  \rangle \rangle_{C}  & 
      \langle \langle   {\cal T}   c^{\dagger}_{\underline x_{2}}(\tau_{2}) c^{\phantom\dagger}_{{\underline x}'_{2}}(\tau'_{2})  \rangle \rangle_{C}  & \dots  &
       \langle \langle   {\cal T}   c^{\dagger}_{\underline x_{2}}(\tau_{2}) c^{\phantom\dagger}_{{\underline x}'_{n}}(\tau'_{n})  \rangle \rangle_{C}   \\
    \vdots & \vdots &  \ddots & \vdots \\
    \langle \langle   {\cal T}   c^{\dagger}_{\underline x_{n}}(\tau_{n}) c^{\phantom\dagger}_{{\underline x}'_{1}}(\tau'_{1})  \rangle \rangle_{C}   & 
     \langle \langle   {\cal T}   c^{\dagger}_{\underline x_{n}}(\tau_{n}) c^{\phantom\dagger}_{{\underline x}'_{2}}(\tau'_{2})  \rangle \rangle_{C}   & \dots  & 
     \langle \langle   {\cal T}   c^{\dagger}_{\underline x_{n}}(\tau_{n}) c^{\phantom\dagger}_{{\underline x}'_{n}}(\tau'_{n})  \rangle \rangle_{C}
 \end{bmatrix}
\end{eqnarray}
In the subroutines   \path{Obser}  and \path{ObserT} of  the module \path{Hamiltonian_Examples.f90} (see Sec.~\ref{sec:obs})   the user is provided with the equal time and time displaced correlation function. Using the  above  formulation  of  Wicks theorem, arbitrary  correlation functions can be computed. We note however, that the program is limited to the calculation of observables that contain only two different imaginary times.  

%------------------------------------------------------------
\subsubsection{Reweighting and the sign problem}\label{sec:reweight}
%------------------------------------------------------------

In general, the action  $S(C) $ will be complex, thereby inhibiting a direct Monte Carlo sampling of $P(C)$.   This leads to the infamous sign problem.     The sign problem is formulation dependent and as noted above, much progress has been made at understanding the class of models that  can be formulated without encountering this problem 
\cite{Wu04,Huffman14,Yao14a,Wei16}.  When the average sign is not too small, we can nevertheless  compute observables within a reweighting scheme.   Here we adopt the following scheme. First  note  that the partition function is real such that: 
\begin{equation}
	Z =   \sum_{C}  e^{-S(C)}    =  \sum_{C}  \overline{e^{-S(C)}} = \sum_{C}  \Re \left[e^{-S(C)} \right]. 
\end{equation}
Thereby\footnote{The attentive reader will have noticed that   for arbitrary Trotter decompositions,  the  imaginary time propagator is not necessarily Hermitian. Thereby, the above equation is correct only up to corrections stemming from the  controlled Trotter systematic error. }
and with the definition
\begin{equation}
\label{Sign.eq}
	 \text{ sign }(C)   =  \frac{   \Re \left[e^{-S(C)} \right]  } {\left| \Re \left[e^{-S(C)} \right]  \right|  }\;,
\end{equation}
the computation of the observable [Eq.~(\ref{eqn:obs})] is re-expressed as follows:
\begin{eqnarray}\label{eqn:obs_rw}
\langle \hat{O}  \rangle  &=&  \frac{\sum_{C}  e^{-S(C)} \langle \langle \hat{O}  \rangle \rangle_{(C)} }{\sum_{C}  e^{-S(C)}}       \nonumber \\ 
                          &=&  \frac{\sum_{C}   \Re \left[e^{-S(C)} \right]    \frac{e^{-S(C)}} {\Re \left[e^{-S(C)} \right]}  \langle \langle \hat{O}  \rangle \rangle_{(C)} }{\sum_{C}   \Re \left[e^{-S(C)} \right]}    \nonumber \\ 
          &=&
   \frac{
     \left\{
      \sum_{C}  \left| \Re \left[e^{-S(C)} \right]  \right|   \text{ sign }(C)   \frac{e^{-S(C)}} {\Re \left[e^{-S(C)} \right]}  \langle \langle \hat{O}  \rangle \rangle_{(C)}  \right\}/
            \sum_{C}  \left| \Re \left[ e^{-S(C)} \right] \right|  
          }  
          { 
          \left\{ \sum_{C}  \left|  \Re \left[ e^{-S(C)} \right]   \right|   \text{ sign }(C) \right\}/
            \sum_{C}   \left| \Re \left[ e^{-S(C)} \right] \right|  
          } \nonumber\\
          &=&
  	 \frac{  \left\langle  \text{ sign }   \frac{e^{-S}} {\Re \left[e^{-S} \right]}  \langle \langle \hat{O}  \rangle \rangle  \right\rangle_{\overline{P}} } { \langle \text{sign}   \rangle_{\overline{P}}}  \;.      
\end{eqnarray} 
The average sign is 
\begin{equation}\label{eqn:sign_rw}
	 \langle \text{sign} \rangle_{\overline{P}} =    \frac { \sum_{C}  \left|  \Re \left[ e^{-S(C)} \right]   \right|   \text{ sign }(C) }  {  \sum_{C}   \left| \Re \left[ e^{-S(C)} \right] \right|  } \;,
\end{equation}
and we have  $\langle \text{sign} \rangle_{\overline{P}} \in \mathbb{R}$ per definition.
According to Eq.~(\ref{eqn:obs_rw}) and Eq.~(\ref{eqn:sign_rw}), the Monte Carlo simulation samples the probability distribution 
\begin{equation}  
	 \overline{P}(C) = \frac{ \left|  \Re \left[ e^{-S(C)} \right] \right| }{\sum_C \left|  \Re \left[ e^{-S(C)} \right]  \right| }\;.
\end{equation}


 
